{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Arranging machine learning projects.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UZ6MhVlLwXu4ekK3-OyXkhPINH7pXAuf",
      "authorship_tag": "ABX9TyPV9DocJn/oELt6bSYsgHjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indrikwijaya/Approaching-Any-ML-Problem/blob/master/3_Arranging_machine_learning_projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKsdrhFJBtRt",
        "outputId": "b994e4cf-cf66-47fe-aed7-d0efcc8cb7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Approaching-Any-ML-Problem\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Approaching-Any-ML-Problem/\n",
        "!mkdir src input models notebooks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train.py\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "def run(fold):\n",
        "  # read the training data with folds\n",
        "  df = pd.read_csv('data/mnist_train_folds.csv')\n",
        "\n",
        "  # training data is where kfold isn't equal to provided fold\n",
        "  # also, note that we reset the index\n",
        "  df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "\n",
        "  # validation data is where kfold is equal to provided fold\n",
        "  df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "  # drop the label column from dataframe and convert it to\n",
        "  # a numpy array by using .values\n",
        "  # target is label column in the dataframe\n",
        "  x_train = df_train.drop('label', axis=1).values\n",
        "  y_train = df_train.label.values\n",
        "\n",
        "  # similarly, for validation, we have\n",
        "  x_valid = df_valid.drop('label', axis=1).values\n",
        "  y_valid = df_valid.label.values\n",
        "\n",
        "  # initialize simple decision tree classifier\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "  # fit the model on training data\n",
        "  clf.fit(x_train, y_train)\n",
        "\n",
        "  # create predictions for validation samples\n",
        "  preds = clf.predict(x_valid)\n",
        "\n",
        "  # accuracy\n",
        "  accuracy = metrics.accuracy_score(y_valid, preds)\n",
        "  print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
        "\n",
        "  # save the model\n",
        "  joblib.dump(clf, f\"models/dt_{fold}.bin\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  run(fold=0)\n",
        "  run(fold=1)\n",
        "  run(fold=2)\n",
        "  run(fold=3)\n",
        "  run(fold=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFxIdViDNof",
        "outputId": "97941d97-e136-4116-a30f-d20588049c01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHS-bog1Ega1",
        "outputId": "774c9c8c-f6e2-4d7a-d047-09830be416b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.8645833333333334\n",
            "Fold=1, Accuracy=0.86975\n",
            "Fold=2, Accuracy=0.8684166666666666\n",
            "Fold=3, Accuracy=0.8715833333333334\n",
            "Fold=4, Accuracy=0.8683333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things are still hardcoded, for example, the fold numbers, the training file and the output folder -> create a config file\n",
        "\n",
        "As you can see, we call the run function multiple times for every fold. Sometimes it’s not advisable to run multiple folds in the same script as the memory consumption may keep increasing, and your program may crash. To take care of this problem, we can pass arguments to the training script. I like doing it using `argparse`."
      ],
      "metadata": {
        "id": "jn8kwXZpE31m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/config.py\n",
        "TRAINING_FILE = \"../data/mnist_train_folds.csv\"\n",
        "MODEL_OUTPUT = \"../models/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufaIgA12EoE_",
        "outputId": "6611bdea-ba5e-4f04-fd56-4331a4dc19df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, update `train.py` accordingly"
      ],
      "metadata": {
        "id": "C5TyIrmaFF5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cZBOdgIFg4o",
        "outputId": "11d19e95-af2d-4f9c-bc74-2b0bd94d189e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Approaching-Any-ML-Problem/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import argparse\n",
        "import joblib\n",
        "import config\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "def run(fold):\n",
        "  # read the training data with folds\n",
        "  df = pd.read_csv(config.TRAINING_FILE)\n",
        "\n",
        "  # training data is where kfold isn't equal to provided fold\n",
        "  # also, note that we reset the index\n",
        "  df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "\n",
        "  # validation data is where kfold is equal to provided fold\n",
        "  df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "  # drop the label column from dataframe and convert it to\n",
        "  # a numpy array by using .values\n",
        "  # target is label column in the dataframe\n",
        "  x_train = df_train.drop('label', axis=1).values\n",
        "  y_train = df_train.label.values\n",
        "\n",
        "  # similarly, for validation, we have\n",
        "  x_valid = df_valid.drop('label', axis=1).values\n",
        "  y_valid = df_valid.label.values\n",
        "\n",
        "  # initialize simple decision tree classifier\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "  # fit the model on training data\n",
        "  clf.fit(x_train, y_train)\n",
        "\n",
        "  # create predictions for validation samples\n",
        "  preds = clf.predict(x_valid)\n",
        "\n",
        "  # accuracy\n",
        "  accuracy = metrics.accuracy_score(y_valid, preds)\n",
        "  print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
        "\n",
        "  # save the model\n",
        "  joblib.dump(clf, \n",
        "              os.path.join(config.MODEL_OUTPUT,\n",
        "              f\"dt_{fold}.bin\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # initialize ArgumentParser class of argparse\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  # add the different arguments you need and their type\n",
        "  parser.add_argument(\n",
        "      \"--fold\",\n",
        "      type=int\n",
        "  )\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  run(fold=args.fold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-7qo8t8FFOA",
        "outputId": "6e3d6b6b-ddc7-4e42-a3fe-a15f5c5ed7f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --fold 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr7LqolQFxzS",
        "outputId": "8086288a-2e3b-4bea-b88f-bdc989b4fb4c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.86925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_5.sh\n",
        "#!/bin/sh\n",
        "python train.py --fold 0\n",
        "python train.py --fold 1\n",
        "python train.py --fold 2\n",
        "python train.py --fold 3\n",
        "python train.py --fold 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou5x0eT7GG10",
        "outputId": "aa4b0174-a757-43da-afa9-4313f57fa2a3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_5.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh train_5.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcyexKqtGdsS",
        "outputId": "040b442d-3bc0-4ec8-f1c0-c9b26e97a5aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.8660833333333333\n",
            "Fold=1, Accuracy=0.8683333333333333\n",
            "Fold=2, Accuracy=0.8695\n",
            "Fold=3, Accuracy=0.86925\n",
            "Fold=4, Accuracy=0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at our training script, we still are limited by a few things, for example, the model. The model is hardcoded in the training script, and the only way to change it is to modify the script. So, we will create a new python script called `model_dispatcher.py`. `model_dispatcher.py`, as the name suggests, will dispatch our models to our training script."
      ],
      "metadata": {
        "id": "uX3R-IWVGpCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_dispatcher.py\n",
        "from sklearn import tree\n",
        "\n",
        "models = {\n",
        "    \"decision_tree_gini\": tree.DecisionTreeClassifier(\n",
        "        criterion=\"gini\"\n",
        "    ),\n",
        "    \"decision_tree_entropy\": tree.DecisionTreeClassifier(\n",
        "        criterion=\"entropy\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I12YzP3eGg19",
        "outputId": "7dbb4f91-a95c-4f92-f3a2-40bcf9b6cdea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_dispatcher.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "\n",
        "import config\n",
        "import model_dispatcher\n",
        "\n",
        "def run(fold, model):\n",
        "  # read the training data with folds\n",
        "  df = pd.read_csv(config.TRAINING_FILE)\n",
        "\n",
        "  # training data is where kfold isn't equal to provided fold\n",
        "  # also, note that we reset the index\n",
        "  df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "\n",
        "  # validation data is where kfold is equal to provided fold\n",
        "  df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "  # drop the label column from dataframe and convert it to\n",
        "  # a numpy array by using .values\n",
        "  # target is label column in the dataframe\n",
        "  x_train = df_train.drop('label', axis=1).values\n",
        "  y_train = df_train.label.values\n",
        "\n",
        "  # similarly, for validation, we have\n",
        "  x_valid = df_valid.drop('label', axis=1).values\n",
        "  y_valid = df_valid.label.values\n",
        "\n",
        "  # initialize simple decision tree classifier\n",
        "  clf = model_dispatcher.models[model]\n",
        "\n",
        "  # fit the model on training data\n",
        "  clf.fit(x_train, y_train)\n",
        "\n",
        "  # create predictions for validation samples\n",
        "  preds = clf.predict(x_valid)\n",
        "\n",
        "  # accuracy\n",
        "  accuracy = metrics.accuracy_score(y_valid, preds)\n",
        "  print(f\"Fold={fold}, Accuracy={accuracy}\")\n",
        "\n",
        "  # save the model\n",
        "  joblib.dump(clf, \n",
        "              os.path.join(config.MODEL_OUTPUT,\n",
        "              f\"dt_{fold}.bin\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # initialize ArgumentParser class of argparse\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  # add the different arguments you need and their type\n",
        "  parser.add_argument(\n",
        "      \"--fold\",\n",
        "      type=int\n",
        "  )\n",
        "  parser.add_argument(\n",
        "      \"--model\",\n",
        "      type=str\n",
        "  )\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  run(\n",
        "      fold=args.fold,\n",
        "      model=args.model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb4beO4HG6E0",
        "outputId": "a41f8b59-4230-46c0-8d52-e2a7500e9651"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --fold 0 --model decision_tree_gini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am9_aeSsHRls",
        "outputId": "f8c10ffe-2993-4a66-8145-182efa2871cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.8661666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --fold 0 --model decision_tree_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtiMlXMDHU2a",
        "outputId": "92d54e7c-2c6d-48e7-b471-2876333ebbd3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can always add new model to `model_dispatcher.py`"
      ],
      "metadata": {
        "id": "tqEwfDwzHZ12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_dispatcher.py\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "\n",
        "models = {\n",
        "    \"decision_tree_gini\": tree.DecisionTreeClassifier(\n",
        "        criterion=\"gini\"\n",
        "    ),\n",
        "    \"decision_tree_entropy\": tree.DecisionTreeClassifier(\n",
        "        criterion=\"entropy\"\n",
        "    ),\n",
        "    \"rf\": ensemble.RandomForestClassifier(),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLUqBh9HHXap",
        "outputId": "8ec51037-4fe4-4fb1-b4a0-bc2ffe8a3550"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_dispatcher.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --fold 0 --model rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waSOWVclHgxm",
        "outputId": "dd5dfbb3-cc44-4219-a7ea-bf91c9378e79"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.9681666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_5_rf.sh\n",
        "#!/bin/sh\n",
        "python train.py --fold 0 --model rf\n",
        "python train.py --fold 1 --model rf\n",
        "python train.py --fold 2 --model rf\n",
        "python train.py --fold 3 --model rf\n",
        "python train.py --fold 4 --model rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sac0JAtSHi6X",
        "outputId": "1c3bac4f-ad0c-484e-ebd1-8c0ca8bf402e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_5_rf.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh train_5_rf.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1nhC5bFHpiW",
        "outputId": "138846a6-6912-4c9e-ed6b-05af9eddd2ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold=0, Accuracy=0.9686666666666667\n",
            "Fold=1, Accuracy=0.969\n",
            "Fold=2, Accuracy=0.96625\n",
            "Fold=3, Accuracy=0.9674166666666667\n",
            "Fold=4, Accuracy=0.9674166666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that I did not import * and neither should you. If I\n",
        "had imported *, you would have never known where the models dictionary came\n",
        "from. Writing good, understandable code is an essential quality one can have, and\n",
        "many data scientists ignore it. If you work on a project that others can understand\n",
        "and use without consulting you, you save their time and your own time and can\n",
        "invest that time to improve your project or work on a new one.\n",
        "\n",
        "You can also use [cookiecutter](https://drivendata.github.io/cookiecutter-data-science/#getting-started) to set up the project directories for you"
      ],
      "metadata": {
        "id": "ATdaHyFVH0pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cookiecutter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_se80-hHsLT",
        "outputId": "34edecb7-bccd-4372-c6a2-958d794b0575"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cookiecutter\n",
            "  Downloading cookiecutter-1.7.3-py2.py3-none-any.whl (34 kB)\n",
            "Collecting jinja2-time>=0.2.0\n",
            "  Downloading jinja2_time-0.2.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter) (6.1.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from cookiecutter) (1.15.0)\n",
            "Collecting poyo>=0.5.0\n",
            "  Downloading poyo-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from cookiecutter) (2.11.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter) (7.1.2)\n",
            "Collecting binaryornot>=0.4.4\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from binaryornot>=0.4.4->cookiecutter) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter) (2.0.1)\n",
            "Collecting arrow\n",
            "  Downloading arrow-1.2.2-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=4.0.0->cookiecutter) (1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from arrow->jinja2-time>=0.2.0->cookiecutter) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from arrow->jinja2-time>=0.2.0->cookiecutter) (2.8.2)\n",
            "Installing collected packages: arrow, poyo, jinja2-time, binaryornot, cookiecutter\n",
            "Successfully installed arrow-1.2.2 binaryornot-0.4.4 cookiecutter-1.7.3 jinja2-time-0.2.0 poyo-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3DJl2_I1tB",
        "outputId": "a3cda5f8-c8dc-494e-f85d-f5c14b1d19fa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cookiecutter https://github.com/drivendata/cookiecutter-data-science\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6mDPy__I3Pi",
        "outputId": "ca73c9b1-1b3f-494b-a450-96969ea6d1b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project_name [project_name]: test\n",
            "repo_name [test]: test\n",
            "author_name [Your name (or your organization/company/team)]: indrik\n",
            "description [A short description of the project.]: testing data science project directory\n",
            "Select open_source_license:\n",
            "1 - MIT\n",
            "2 - BSD-3-Clause\n",
            "3 - No license file\n",
            "Choose from 1, 2, 3 [1]: 1\n",
            "s3_bucket [[OPTIONAL] your-bucket-for-syncing-data (do not include 's3://')]: \n",
            "aws_profile [default]: \n",
            "Select python_interpreter:\n",
            "1 - python3\n",
            "2 - python\n",
            "Choose from 1, 2 [1]: 1\n",
            "\n",
            "\n",
            "=============================================================================\n",
            "*** DEPRECATION WARNING ***\n",
            "\n",
            "Cookiecutter data science is moving to v2 soon, which will entail using\n",
            "the command `ccds ...` rather than `cookiecutter ...`. The cookiecutter command\n",
            "will continue to work, and this version of the template will still be available.\n",
            "To use the legacy template, you will need to explicitly use `-c v1` to select it.\n",
            "\n",
            "Please update any scripts/automation you have to append the `-c v1` option,\n",
            "which is available now.\n",
            "\n",
            "For example:\n",
            "    cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science\n",
            "=============================================================================\n",
            "\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "├── LICENSE\n",
        "├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
        "├── README.md          <- The top-level README for developers using this project.\n",
        "├── data\n",
        "│   ├── external       <- Data from third party sources.\n",
        "│   ├── interim        <- Intermediate data that has been transformed.\n",
        "│   ├── processed      <- The final, canonical data sets for modeling.\n",
        "│   └── raw            <- The original, immutable data dump.\n",
        "│\n",
        "├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
        "│\n",
        "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
        "│\n",
        "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
        "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
        "│                         `1.0-jqp-initial-data-exploration`.\n",
        "│\n",
        "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
        "│\n",
        "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
        "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
        "│\n",
        "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
        "│                         generated with `pip freeze > requirements.txt`\n",
        "│\n",
        "├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n",
        "├── src                <- Source code for use in this project.\n",
        "│   ├── __init__.py    <- Makes src a Python module\n",
        "│   │\n",
        "│   ├── data           <- Scripts to download or generate data\n",
        "│   │   └── make_dataset.py\n",
        "│   │\n",
        "│   ├── features       <- Scripts to turn raw data into features for modeling\n",
        "│   │   └── build_features.py\n",
        "│   │\n",
        "│   ├── models         <- Scripts to train models and then use trained models to make\n",
        "│   │   │                 predictions\n",
        "│   │   ├── predict_model.py\n",
        "│   │   └── train_model.py\n",
        "│   │\n",
        "│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
        "│       └── visualize.py\n",
        "│\n",
        "└── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n",
        "```\n"
      ],
      "metadata": {
        "id": "DVaI93C7JIvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Clmo4Tv_I5p8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}